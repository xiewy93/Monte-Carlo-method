#This scripy tests two different models (GBR and OLS) on a small subset of data from 2012.

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

#Import the 2012 subset of data
loads = pd.read_csv('load2012.csv')
weather = pd.read_csv('weather2012.csv')

# Format datetime columns
weather['date'] = weather.dateutc.apply(lambda x: pd.to_datetime(x).date())
weather['timeest'] = weather.timeest.apply(lambda x: pd.to_datetime(x).time())
foo = weather[['date', 'timeest']].astype(str)
weather['timestamp'] = pd.to_datetime(foo['date'] + ' ' + foo['timeest'])
loads['timestamp'] = loads.timestamp.apply(lambda x: pd.to_datetime(x))

#Add weather data to loads data
from sklearn.neighbors import NearestNeighbors

def find_nearest(group, match, groupname):
    nbrs = NearestNeighbors(1).fit(match['timestamp'].values[:, None])
    dist, ind = nbrs.kneighbors(group['timestamp'].values[:, None])

    group['nearesttime'] = match['timestamp'].values[ind.ravel()]
    return group

loads = find_nearest(loads,weather,'timestamp')
full = loads.merge(weather, left_on='nearesttime', right_on='timestamp')

#Remove and rename redundant columns 
full = full[['timestamp_x', 'load', 'nearesttime', 'temperaturef', \
            'dewpointf', 'humidity', 'sealevelpressurein', 'winddirection', 'windspeedmph', \
            'precipitationin']].rename(columns={'timestamp_x': 'timestamp', 'nearesttime':'weathertime'})

#Checkpoint: export data to csv
full.to_csv('full2012.csv', index=False)

# Create features who applied probabalistic modeling techniques (such as Gradient-Boosting Regression) to forecast electricity prices:
#`dow`: day of the week (integer 0-6)
#`doy`: day of the year (integer 0-365)
#`day`: day of the month (integer 1-31)
#`woy`: week of the year (integer 1-52)
#`month`: month of the year (integer 1-12)
#`hour`: hour of the day (integer 0-23)
#`minute`: minute of the day (integer 0-1339)

#`t_m24`: load value from 24 hours earlier
#`t_m48`: load value from 48 hours earlier
#`tdif`: difference between load and t_m24

#datetime value of one day
pday = pd.Timedelta('1 day')

def get_prev_days(x, n_days):
    '''Take a datetime (x) in the 'full' dataframe, and outputs the load value n_days before that datetime'''
    try:
        lo = full[full.timestamp == x - n_days*pday].load.values[0]
    except:
        lo = full[full.timestamp == x].load.values[0]
    return lo

full['dow'] = full.timestamp.apply(lambda x: x.dayofweek)
full['doy'] = full.timestamp.apply(lambda x: x.dayofyear)
full['day'] = full.timestamp.apply(lambda x: x.day)
full['month'] = full.timestamp.apply(lambda x: x.month)
full['hour'] = full.timestamp.apply(lambda x: x.hour)
full['minute'] = full.timestamp.apply(lambda x: x.hour*60 + x.minute)

full['t_m24'] = full.timestamp.apply(get_prev_days, args=(1,))
full['t_m48'] = full.timestamp.apply(get_prev_days, args=(2,))
full['tdif'] = full['load'] - full['t_m24']

full.to_csv('full2012_features.csv', index=False)

#Gradient Boosting Regression
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.cross_validation import train_test_split

full.columns
X = full[['temperaturef','dewpointf', 'humidity', 'sealevelpressurein', 'windspeedmph', \
          'precipitationin','dow','doy', 'month','hour','minute','t_m24', 't_m48', 'tdif']]
y = full['load']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)
gbr = GradientBoostingRegressor(loss='ls', verbose=1, warm_start=True)
gbr_fitted = gbr.fit(X_train, y_train)
gbr.score(X_test, y_test)
gbr.score(X_train, y_train)

#Ordinary Least Squares Regression
import statsmodels.api as sm

model = sm.OLS(y,X)
results = model.fit()
results.summary()

from sklearn.metrics import mean_squared_error
from sklearn.linear_model import Ridge

avg_MSE = []
alphas = np.linspace(-2, 8, 20, endpoint=False)
alphas
for alpha in alphas:
    MSE = []
    for i in range(20):
#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)
#     model = sm.OLS(X_train, y_train)
        model = Ridge(alpha=alpha)
        model.fit(X_test, y_test)
        test_error = mean_squared_error(y_test, model.predict(X_test))
        MSE.append(test_error)
    avg_MSE.append(np.mean(MSE))

plt.figure(figsize=(6,2))
plt.xlabel('alpha', fontsize=14)
plt.ylabel('Cross Validation MSE', fontsize=11)
plt.title('alpha vs. Cross Validation MSE', fontsize=11)
plt.plot(alphas, avg_MSE)







































